== 2009-11-09 ==

TODO: CODE: acrescentar filtro de ds em todos os métodos

Me bati com Italo e ele me disse como acessar o banco de dados a partir de uma
máquina de fora: usando tunel ssh!
$ ssh -p 1998 mainha -L 3128:localhost:5555
Depois disso é só acessar o banco via localhost:3128

--

Questões que eu posso querer responder com a minha pesquisa:

*** Quais algoritmos de clustering são ruins em todos os casos?

Problema: o que é um algoritmo ruim?
Variação: algoritmo X é ruim em n% dos casos, algoritmo Y é ruim em m%...

*** Quais algoritmos de clustering são bons em todos os casos?

O que é um algoritmo bom?
Existem algoritmos bons em todos os casos?

*** Descontando métricas de rede (densidade etc.), o modelo particular usado
influencia os resultados do clustering?

Usar técnicas de classificação pra descobrir isso?


== 2009-11-06 ==

O clusterer de Anquetil empacou nas quatro maquinas do cluster.
Mainha: I, [2009-11-05T15:43:54.645800 #31899]  INFO -- : prune -s0.9 | pprint
Huguinho: I, [2009-11-05T15:14:05.152599 #30344]  INFO -- : prune -s0.9 | pprint
Zezinho: I, [2009-11-05T15:35:13.356031 #4387]  INFO -- : prune -s0.75 | pprint
Luisinho: I, [2009-11-05T15:14:36.402707 #8915]  INFO -- : prune -s0.75 | pprint
O problema parece ser no prune. Veja top em mainha:
 4301 rodrigo   20   0  6288  532  420 R   98  0.0   1369:24 prune              
 1973 rodrigo   20   0  6292  448  420 R   98  0.0   1392:28 prune             
Pra dar um jeito eu coloquei um timeout de 10 segundos para o clusterer.

O timeout do Ruby nao funciona. Dar uma olhada no timeout em bash:
http://www.bashcookbook.com/bashinfo/source/bash-4.0/examples/scripts/timeout3

== 2009-11-04 ==

Criei uma instalação independente do postgresql no meu home, escutando na 
porta 5555. Migrei os dados pra lá.
Referências:
http://www.thegeekstuff.com/2009/04/linux-postgresql-install-and-configure-from-source/
http://www.postgresql.org/docs/8.2/static/migration.html

Para rodar o banco: ~/shared/opt/postgresql/bin/postgres

== 2009-10-23 ==

Anotações após conversa com Roberto e Katyusco
  - Analisar distribuição de diversos atributos dos 65 softwares (n vertices,
n modulos, densidade de arestas, tam menor modulo, proporcao de arestas 
externas...)
  - Talvez fazer analises bivariadas
  - Ajustar parametros dos modelos de acordo com as distribuições encontradas nos
65 softwares
  --
  - Determinar o mojo médio de cada algoritmo de clustering, quantas vezes em média
ele é melhor do que os outros...
  - Usar algoritmo de classificação supervisionada pra tentar achar padrões entre
atributos de uma rede e desempenho de um algoritmo de clustering
  --
  - Estabelecer relacao algébrica entre parâmetros e atributos?

--
-- mojosim médio por algoritmo de clustering para redes realistas
--
rodrigo=> SELECT nme_clusterer_config, 1.0 - AVG(mojo / n_vertices::float) AS mojosim
rodrigo-> FROM view_decomposition
rodrigo-> WHERE s_score >= 0.88
rodrigo-> GROUP by 1
rodrigo-> ORDER by 2;
 nme_clusterer_config |      mojosim
----------------------+-------------------
 CL75                 | 0.260369954941326
 SL75                 | 0.283744748484687
 SL90                 | 0.334667243109811
 ACDC                 | 0.456499819679419
 CL90                 | 0.487591551884503
 Infomap              | 0.508317384657187
 Bunch                | 0.640774390243903
                      |                 1

O Bunch é visivelmente superior aos demais, em média.
TODO: Fazer análise separando por modelo

--
-- Em quantas redes cada algoritmo foi o melhor
--
SELECT nme_clusterer_config AS best, COUNT(*) AS times
FROM (
SELECT dec.nme_clusterer_config
FROM view_decomposition dec
INNER JOIN (SELECT v.fk_network, MIN(v.mojo) AS mojo
 FROM view_decomposition v
 WHERE v.fk_clusterer_config IS NOT NULL
 GROUP BY v.fk_network) AS mins ON dec.fk_network = mins.fk_network AND mins.mojo = dec.mojo
) AS x GROUP BY 1 ORDER BY 2;
  best   | times
---------+-------
 SL75    |    19
 Bunch   |    64
 SL90    |   223
         |   244
 CL90    |   681
 ACDC    |   846
 Infomap |  1453
(7 registros)

--
-- Em quantas redes cada algoritmo foi o pior
--
SELECT nme_clusterer_config AS worst, COUNT(*) AS times
FROM (
SELECT dec.nme_clusterer_config
FROM view_decomposition dec
INNER JOIN (SELECT v.fk_network, MAX(v.mojo) AS mojo
 FROM view_decomposition v
 WHERE v.fk_clusterer_config IS NOT NULL
 GROUP BY v.fk_network) AS mins ON dec.fk_network = mins.fk_network AND mins.mojo = dec.mojo
) AS x GROUP BY 1 ORDER BY 2;
  worst  | times
---------+-------
 Infomap |    46
 ACDC    |   104
 SL75    |   667
 SL90    |   712
 CL75    |  1725
(5 registros)


As tríades estavam retornando 0, 0, 0, 0... Consulta para anular essas tríades:
UPDATE triads
SET triad1 = NULL,
triad2 = NULL,
triad3 = NULL,
triad4 = NULL,
triad5 = NULL,
triad6 = NULL,
triad7 = NULL,
triad8 = NULL,
triad9 = NULL,
triad10 = NULL,
triad11 = NULL,
triad12 = NULL,
triad13 = NULL
WHERE triad1 + triad2 + triad3 + triad4 = 0;

== 2009-10-21 ==

implemented s_score computation. almost all networks are realistic.

it is difficult to compare results from distinct models because the parameters
are distinct. we must collect metrics on the networks (e.g., edge density,
proportion of external edges, number of modules etc.) and then group data by
metric value. for example:
model | edge density | mojosim
------+--------------+---------
lf    | 0.5          | 0.8
bcr+  | 0.5          | 0.5
lf    | 0.7          | 0.3
bcr+  | 0.7          | 0.4
-
lf would be a data series and bcr+, another.

-- nmi vs. n_edges
select trunc(n_edges / 1000), avg(nmi), count(*)
from view_decomposition
where n_vertices = 1000
and synthetic = true
group by 1
order by 1;

 trunc |        avg        | count
-------+-------------------+-------
     4 | 0.634527621926318 |   864
     5 | 0.614459920324599 |  3600
    11 | 0.361310819978571 |   304
    12 | 0.354199885132471 |  1712
    13 | 0.350848016541615 |  2704
    14 | 0.336048726340844 |  1976
    15 | 0.349672880516257 |   504
    19 | 0.739031774785182 |   792

result: nmi deteriorates when n_edges increase, except when there are 19000
edges (why?)

------------------------------------------------------------------------------

experiment.

measure authoritativeness and ned.

use mojosim.
define ned based on min module size and max module size for each model.

------------------------------------------------------------------------------
postgresql schemas are namespaces. useful to isolate data from distinct
experiments.

consider using table inheritance (model_params <|-- bcr_params, cgw_params, 
lf_params ; network <|-- synthetic_net, natural_net)
- not feasible. primary key index is not shared among parent/child tables
- p of eaa suggests merging all columns into one big table


